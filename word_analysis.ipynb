{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting Data\n",
    "\n",
    "Collects data from wikipedia pages, saves them and extract unique words and their's frequencies to uses on word structure analysis. It also checks if the language corpora it's already collected to skip calling the API multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libs\n",
    "import wikipedia\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T01:03:41.254522Z",
     "start_time": "2023-08-11T01:03:41.225557Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavra</th>\n",
       "      <th>Frequencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>psb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>formam</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3395</th>\n",
       "      <td>documentos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>marinha</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4260</th>\n",
       "      <td>competição</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>tupiniquins</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577</th>\n",
       "      <td>compreendendo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>elegem</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>habitats</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>alimentício</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>tribunais</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>chamada</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5053</th>\n",
       "      <td>impediriam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>barreto</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>transferida</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3359</th>\n",
       "      <td>caput</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>restringiram</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4197</th>\n",
       "      <td>detenha</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>gradualmente</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>disponíveis</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>majoritariamente</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4778</th>\n",
       "      <td>vias</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>voltaram</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>fosso</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>pico</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5172</th>\n",
       "      <td>concise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5473</th>\n",
       "      <td>atrelada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>jair</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>tamanduás</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4475</th>\n",
       "      <td>internalização</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>movimentado</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>atacou</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>desigualdade</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>organizou</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4134</th>\n",
       "      <td>alguém</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2243</th>\n",
       "      <td>atribuídos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>posse</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>arnaldo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>baseada</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>incertezas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>contribuição</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5236</th>\n",
       "      <td>rendeu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548</th>\n",
       "      <td>porção</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4875</th>\n",
       "      <td>profissão</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>homem</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4203</th>\n",
       "      <td>preferindo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5161</th>\n",
       "      <td>monetarismo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>luso</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>devida</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>policiamento</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Palavra  Frequencia\n",
       "2003               psb           1\n",
       "117             formam           3\n",
       "3395        documentos           1\n",
       "2139           marinha           3\n",
       "4260        competição           6\n",
       "484        tupiniquins           1\n",
       "3577     compreendendo           2\n",
       "3315            elegem           3\n",
       "146           habitats           4\n",
       "2364       alimentício           1\n",
       "766          tribunais           6\n",
       "252            chamada          12\n",
       "5053        impediriam           1\n",
       "2914           barreto           2\n",
       "211        transferida           1\n",
       "3359             caput           1\n",
       "1166      restringiram           1\n",
       "4197           detenha           1\n",
       "5005      gradualmente           1\n",
       "3187       disponíveis           6\n",
       "43    majoritariamente           3\n",
       "4778              vias           1\n",
       "1232          voltaram           1\n",
       "1570             fosso           1\n",
       "1578              pico           1\n",
       "5172           concise           1\n",
       "5473          atrelada           1\n",
       "1337              jair           1\n",
       "1646         tamanduás           1\n",
       "4475    internalização           1\n",
       "2641       movimentado           2\n",
       "1383            atacou           1\n",
       "326       desigualdade           3\n",
       "3261         organizou           1\n",
       "4134            alguém           1\n",
       "2243        atribuídos           1\n",
       "1112             posse           3\n",
       "2901           arnaldo           1\n",
       "2207           baseada           4\n",
       "2599        incertezas           1\n",
       "3072      contribuição           2\n",
       "5236            rendeu           1\n",
       "3548            porção           3\n",
       "4875         profissão           2\n",
       "3843             homem           4\n",
       "4203        preferindo           1\n",
       "5161       monetarismo           1\n",
       "502               luso           2\n",
       "4461            devida           1\n",
       "3434      policiamento           1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up directory and file paths\n",
    "corpus_dir = Path(\"language_corpora\")\n",
    "corpus_dir.mkdir(exist_ok=True)\n",
    "corpus_file = corpus_dir / \"portuguese_corpus.txt\"\n",
    "\n",
    "# Set Wikipedia language to Portuguese\n",
    "wikipedia.set_lang(\"pt\")\n",
    "\n",
    "# List of common Portuguese Wikipedia page topics\n",
    "search_terms = [\"Brasil\", \"Econômia\", \"Futebol\", \"História\", \"Cultura\"]\n",
    "\n",
    "# Collect text from Wikipedia pages\n",
    "def collect_wikipedia_text(search_terms, results_limit=2):\n",
    "    collected_texts = []\n",
    "    total_words = 0\n",
    "    min_content_length = 500\n",
    "    target_words = 20000\n",
    "\n",
    "    for term in search_terms:\n",
    "        if total_words >= target_words:\n",
    "            break\n",
    "        try:\n",
    "            search_results = wikipedia.search(term, results=results_limit)\n",
    "            for title in search_results:\n",
    "                if total_words >= target_words:\n",
    "                    break\n",
    "                try:\n",
    "                    page = wikipedia.page(title, auto_suggest=False)\n",
    "                    content = page.content\n",
    "                    word_count = len(content.split())\n",
    "                    if word_count > min_content_length:\n",
    "                        collected_texts.append(content)\n",
    "                        total_words += word_count\n",
    "                    time.sleep(1)\n",
    "                except (wikipedia.exceptions.PageError, wikipedia.exceptions.DisambiguationError):\n",
    "                    pass\n",
    "                except Exception:\n",
    "                    pass\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return '\\n'.join(collected_texts)\n",
    "\n",
    "# Check if corpus exists and has sufficient words\n",
    "min_words = 20000\n",
    "if corpus_file.exists():\n",
    "    with open(corpus_file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    word_count = len(text.split())\n",
    "    if word_count >= min_words:\n",
    "        pass  # Use existing corpus\n",
    "    else:\n",
    "        text = collect_wikipedia_text(search_terms)\n",
    "        if text and len(text.split()) >= min_words:\n",
    "            with open(corpus_file, 'w', encoding='utf-8') as f:\n",
    "                f.write(text)\n",
    "else:\n",
    "    text = collect_wikipedia_text(search_terms)\n",
    "    if text and len(text.split()) >= min_words:\n",
    "        with open(corpus_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(text)\n",
    "\n",
    "# Check if text was retrieved or loaded\n",
    "if not text:\n",
    "    exit()\n",
    "\n",
    "# Clean the text: keep letters and diacritics, remove numbers, punctuation, spaces, etc.\n",
    "words = re.findall(r'[a-záéíóúâêîôûãõç]+', text.lower())\n",
    "\n",
    "# Count word frequencies\n",
    "word_counts = Counter(words)\n",
    "\n",
    "# Create DataFrame with words and their frequencies\n",
    "df = pd.DataFrame(list(word_counts.items()), columns=['Palavra', 'Frequencia'])\n",
    "\n",
    "# Sort by frequency and sample 10 random words\n",
    "df = df.sort_values(by='Frequencia', ascending=False).sample(50)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encontrando Sílabas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T01:03:41.270437Z",
     "start_time": "2023-08-11T01:03:41.258469Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cria uma lista de vogais\n",
    "vogais = ['a', 'e', 'i', 'o', 'u', 'á', 'é', 'í', 'ó', 'ú', 'â', 'ê', 'ô', 'ã', 'õ', 'ão', 'õe', 'ãe']\n",
    "\n",
    "# Cria uma lista de consoantes que aceitam CA\n",
    "consoantes_ca = ['b', 'c', 'd', 'f', 'g', 'p', 't']\n",
    "\n",
    "# Cria uma lista de consoantes auxiliares (CA)\n",
    "consoantes_auxiliares = ['l', 'r']\n",
    "\n",
    "# Cria uma lista de consoantes de coda (CC)\n",
    "consoantes_coda = ['m', 'n', 'r', 'l', 'z', 's', 'x']\n",
    "codas = consoantes_coda\n",
    "\n",
    "# Cria uma lista de consoantes que não aceitam CA\n",
    "consoantes_nao_ca = ['h', 'j', 'm', 'n', 'r', 'l', 's', 'v', 'x', 'z', 'lh', 'nh', 'qu', 'gu', 'ch', 'ç']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T01:03:41.300565Z",
     "start_time": "2023-08-11T01:03:41.272432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>silabas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>çãer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4208</th>\n",
       "      <td>çãel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4209</th>\n",
       "      <td>çãez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4210</th>\n",
       "      <td>çães</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4211</th>\n",
       "      <td>çãex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4212 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     silabas\n",
       "0          a\n",
       "1         am\n",
       "2         an\n",
       "3        ans\n",
       "4         ar\n",
       "...      ...\n",
       "4207    çãer\n",
       "4208    çãel\n",
       "4209    çãez\n",
       "4210    çães\n",
       "4211    çãex\n",
       "\n",
       "[4212 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gerar_silabas(vogais, consoantes_ca, consoantes_auxiliares, consoantes_coda, consoantes_nao_ca):\n",
    "    silabas = []\n",
    "    \n",
    "    # Using only vogais\n",
    "    for vogal in vogais:\n",
    "        silabas.append(vogal)\n",
    "        for cc in consoantes_coda:\n",
    "            silabas.append(vogal + cc)\n",
    "            if cc == 'n':\n",
    "                silabas.append(vogal + cc + 's')\n",
    "                \n",
    "    # Using consoantes_ca\n",
    "    for consoante in consoantes_ca:\n",
    "        for vogal in vogais:\n",
    "            silabas.append(consoante + vogal)\n",
    "            for cc in consoantes_coda:\n",
    "                silabas.append(consoante + vogal + cc)\n",
    "                if cc == 'n':\n",
    "                    silabas.append(consoante + vogal + cc + 's')\n",
    "                    \n",
    "    # Using consoantes_auxiliares\n",
    "    for consoante in consoantes_auxiliares:\n",
    "        for vogal in vogais:\n",
    "            silabas.append(consoante + vogal)\n",
    "            for cc in consoantes_coda:\n",
    "                silabas.append(consoante + vogal + cc)\n",
    "                if cc == 'n':\n",
    "                    silabas.append(consoante + vogal + cc + 's')\n",
    "                    \n",
    "    # Using consoantes_nao_ca\n",
    "    for consoante in consoantes_nao_ca:\n",
    "        for vogal in vogais:\n",
    "            silabas.append(consoante + vogal)\n",
    "            for cc in consoantes_coda:\n",
    "                silabas.append(consoante + vogal + cc)\n",
    "                if cc == 'n':\n",
    "                    silabas.append(consoante + vogal + cc + 's')\n",
    "    \n",
    "    return silabas\n",
    "\n",
    "# Chama a função com os parâmetros especificados\n",
    "resultado = gerar_silabas(vogais, consoantes_ca, consoantes_auxiliares, consoantes_coda, consoantes_nao_ca)\n",
    "\n",
    "# Converte em um dataframe\n",
    "silabas = pd.DataFrame(resultado, columns=['silabas'])\n",
    "\n",
    "silabas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T01:03:41.331593Z",
     "start_time": "2023-08-11T01:03:41.318791Z"
    }
   },
   "outputs": [],
   "source": [
    "def match_syllable_from_start(word, patterns, next_char_cond=None):\n",
    "    \"\"\"Return the longest syllable from the start of the word that matches a pattern.\"\"\"\n",
    "    max_syllable = ''\n",
    "    for pattern in patterns:\n",
    "        if word.startswith(pattern) and len(pattern) > len(max_syllable):\n",
    "            # If there's a condition to check the character after the matched pattern\n",
    "            next_char_index = len(pattern)\n",
    "            if next_char_cond:\n",
    "                # Either the word ends after the coda, or the next character satisfies the condition\n",
    "                if next_char_index == len(word) or (next_char_index < len(word) and next_char_cond(word[next_char_index])):\n",
    "                    max_syllable = pattern\n",
    "            else:\n",
    "                max_syllable = pattern\n",
    "    return max_syllable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T01:03:41.363531Z",
     "start_time": "2023-08-11T01:03:41.333578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavra</th>\n",
       "      <th>Frequencia</th>\n",
       "      <th>Identified_Syllables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>psb</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>formam</td>\n",
       "      <td>3</td>\n",
       "      <td>[for, mam]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3395</th>\n",
       "      <td>documentos</td>\n",
       "      <td>1</td>\n",
       "      <td>[do, cu, men, tos]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>marinha</td>\n",
       "      <td>3</td>\n",
       "      <td>[ma, ri, nha]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4260</th>\n",
       "      <td>competição</td>\n",
       "      <td>6</td>\n",
       "      <td>[com, pe, ti, ção]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>tupiniquins</td>\n",
       "      <td>1</td>\n",
       "      <td>[tu, pi, ni, quin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577</th>\n",
       "      <td>compreendendo</td>\n",
       "      <td>2</td>\n",
       "      <td>[com, pre, en, den, do]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>elegem</td>\n",
       "      <td>3</td>\n",
       "      <td>[e, le, gem]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>habitats</td>\n",
       "      <td>4</td>\n",
       "      <td>[ha, bi, ta]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>alimentício</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, li, men, tí, ci, o]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>tribunais</td>\n",
       "      <td>6</td>\n",
       "      <td>[tri, bu, na, is]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>chamada</td>\n",
       "      <td>12</td>\n",
       "      <td>[cha, ma, da]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5053</th>\n",
       "      <td>impediriam</td>\n",
       "      <td>1</td>\n",
       "      <td>[im, pe, di, ri, am]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>barreto</td>\n",
       "      <td>2</td>\n",
       "      <td>[bar, re, to]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>transferida</td>\n",
       "      <td>1</td>\n",
       "      <td>[tran, fe, ri, da]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3359</th>\n",
       "      <td>caput</td>\n",
       "      <td>1</td>\n",
       "      <td>[ca, pu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>restringiram</td>\n",
       "      <td>1</td>\n",
       "      <td>[res, trin, gi, ram]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4197</th>\n",
       "      <td>detenha</td>\n",
       "      <td>1</td>\n",
       "      <td>[de, te, nha]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>gradualmente</td>\n",
       "      <td>1</td>\n",
       "      <td>[gra, du, al, men, te]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>disponíveis</td>\n",
       "      <td>6</td>\n",
       "      <td>[dis, po, ní, ve, is]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>majoritariamente</td>\n",
       "      <td>3</td>\n",
       "      <td>[ma, jo, ri, ta, ri, a, men, te]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4778</th>\n",
       "      <td>vias</td>\n",
       "      <td>1</td>\n",
       "      <td>[vi, as]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>voltaram</td>\n",
       "      <td>1</td>\n",
       "      <td>[vol, ta, ram]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>fosso</td>\n",
       "      <td>1</td>\n",
       "      <td>[fos, so]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>pico</td>\n",
       "      <td>1</td>\n",
       "      <td>[pi, co]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5172</th>\n",
       "      <td>concise</td>\n",
       "      <td>1</td>\n",
       "      <td>[con, ci, se]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5473</th>\n",
       "      <td>atrelada</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, tre, la, da]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>jair</td>\n",
       "      <td>1</td>\n",
       "      <td>[ja, ir]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>tamanduás</td>\n",
       "      <td>1</td>\n",
       "      <td>[ta, man, du, ás]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4475</th>\n",
       "      <td>internalização</td>\n",
       "      <td>1</td>\n",
       "      <td>[in, ter, na, li, za, ção]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>movimentado</td>\n",
       "      <td>2</td>\n",
       "      <td>[mo, vi, men, ta, do]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>atacou</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, ta, co, u]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>desigualdade</td>\n",
       "      <td>3</td>\n",
       "      <td>[de, si, gual, da, de]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>organizou</td>\n",
       "      <td>1</td>\n",
       "      <td>[or, ga, ni, zo, u]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4134</th>\n",
       "      <td>alguém</td>\n",
       "      <td>1</td>\n",
       "      <td>[al, guém]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2243</th>\n",
       "      <td>atribuídos</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, tri, bu, í, dos]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>posse</td>\n",
       "      <td>3</td>\n",
       "      <td>[pos, se]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>arnaldo</td>\n",
       "      <td>1</td>\n",
       "      <td>[ar, nal, do]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>baseada</td>\n",
       "      <td>4</td>\n",
       "      <td>[ba, se, a, da]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>incertezas</td>\n",
       "      <td>1</td>\n",
       "      <td>[in, cer, te, zas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>contribuição</td>\n",
       "      <td>2</td>\n",
       "      <td>[con, tri, bu, i, ção]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5236</th>\n",
       "      <td>rendeu</td>\n",
       "      <td>1</td>\n",
       "      <td>[ren, de, u]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548</th>\n",
       "      <td>porção</td>\n",
       "      <td>3</td>\n",
       "      <td>[por, ção]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4875</th>\n",
       "      <td>profissão</td>\n",
       "      <td>2</td>\n",
       "      <td>[pro, fis, são]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>homem</td>\n",
       "      <td>4</td>\n",
       "      <td>[ho, mem]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4203</th>\n",
       "      <td>preferindo</td>\n",
       "      <td>1</td>\n",
       "      <td>[pre, fe, rin, do]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5161</th>\n",
       "      <td>monetarismo</td>\n",
       "      <td>1</td>\n",
       "      <td>[mo, ne, ta, ris, mo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>luso</td>\n",
       "      <td>2</td>\n",
       "      <td>[lu, so]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>devida</td>\n",
       "      <td>1</td>\n",
       "      <td>[de, vi, da]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>policiamento</td>\n",
       "      <td>1</td>\n",
       "      <td>[po, li, ci, a, men, to]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Palavra  Frequencia              Identified_Syllables\n",
       "2003               psb           1                                []\n",
       "117             formam           3                        [for, mam]\n",
       "3395        documentos           1                [do, cu, men, tos]\n",
       "2139           marinha           3                     [ma, ri, nha]\n",
       "4260        competição           6                [com, pe, ti, ção]\n",
       "484        tupiniquins           1                [tu, pi, ni, quin]\n",
       "3577     compreendendo           2           [com, pre, en, den, do]\n",
       "3315            elegem           3                      [e, le, gem]\n",
       "146           habitats           4                      [ha, bi, ta]\n",
       "2364       alimentício           1           [a, li, men, tí, ci, o]\n",
       "766          tribunais           6                 [tri, bu, na, is]\n",
       "252            chamada          12                     [cha, ma, da]\n",
       "5053        impediriam           1              [im, pe, di, ri, am]\n",
       "2914           barreto           2                     [bar, re, to]\n",
       "211        transferida           1                [tran, fe, ri, da]\n",
       "3359             caput           1                          [ca, pu]\n",
       "1166      restringiram           1              [res, trin, gi, ram]\n",
       "4197           detenha           1                     [de, te, nha]\n",
       "5005      gradualmente           1            [gra, du, al, men, te]\n",
       "3187       disponíveis           6             [dis, po, ní, ve, is]\n",
       "43    majoritariamente           3  [ma, jo, ri, ta, ri, a, men, te]\n",
       "4778              vias           1                          [vi, as]\n",
       "1232          voltaram           1                    [vol, ta, ram]\n",
       "1570             fosso           1                         [fos, so]\n",
       "1578              pico           1                          [pi, co]\n",
       "5172           concise           1                     [con, ci, se]\n",
       "5473          atrelada           1                  [a, tre, la, da]\n",
       "1337              jair           1                          [ja, ir]\n",
       "1646         tamanduás           1                 [ta, man, du, ás]\n",
       "4475    internalização           1        [in, ter, na, li, za, ção]\n",
       "2641       movimentado           2             [mo, vi, men, ta, do]\n",
       "1383            atacou           1                    [a, ta, co, u]\n",
       "326       desigualdade           3            [de, si, gual, da, de]\n",
       "3261         organizou           1               [or, ga, ni, zo, u]\n",
       "4134            alguém           1                        [al, guém]\n",
       "2243        atribuídos           1              [a, tri, bu, í, dos]\n",
       "1112             posse           3                         [pos, se]\n",
       "2901           arnaldo           1                     [ar, nal, do]\n",
       "2207           baseada           4                   [ba, se, a, da]\n",
       "2599        incertezas           1                [in, cer, te, zas]\n",
       "3072      contribuição           2            [con, tri, bu, i, ção]\n",
       "5236            rendeu           1                      [ren, de, u]\n",
       "3548            porção           3                        [por, ção]\n",
       "4875         profissão           2                   [pro, fis, são]\n",
       "3843             homem           4                         [ho, mem]\n",
       "4203        preferindo           1                [pre, fe, rin, do]\n",
       "5161       monetarismo           1             [mo, ne, ta, ris, mo]\n",
       "502               luso           2                          [lu, so]\n",
       "4461            devida           1                      [de, vi, da]\n",
       "3434      policiamento           1          [po, li, ci, a, men, to]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def identify_syllables_in_word(word, vogais, consoantes_ca, consoantes_auxiliares, consoantes_coda, consoantes_nao_ca):\n",
    "    identified_syllables = []\n",
    "    i = 0\n",
    "\n",
    "    # Patterns list comprehension\n",
    "    ca_vc_coda = [con + ca + v + co for con in consoantes_ca for ca in consoantes_auxiliares for v in vogais for co in consoantes_coda]\n",
    "    c_v_coda = [con + v + co for con in (consoantes_ca + consoantes_nao_ca) for v in vogais for co in consoantes_coda]\n",
    "    ca_v = [con + ca + v for con in consoantes_ca for ca in consoantes_auxiliares for v in vogais]\n",
    "    c_v = [con + v for con in (consoantes_ca + consoantes_nao_ca) for v in vogais]\n",
    "    v_coda = [v + co for v in vogais for co in consoantes_coda]\n",
    "    \n",
    "    while i < len(word):\n",
    "        patterns = [ca_vc_coda, c_v_coda, ca_v, c_v, v_coda, vogais]\n",
    "        \n",
    "        matched = False\n",
    "        for pattern_list in patterns:\n",
    "            syllable = match_syllable_from_start(word[i:], pattern_list)\n",
    "            \n",
    "            # For codas, check if it should be retained as a coda or act as the starting consonant of the next syllable\n",
    "            if syllable and syllable[-1] in consoantes_coda:\n",
    "                next_char_index = i + len(syllable)\n",
    "                if next_char_index < len(word):\n",
    "                    next_char = word[next_char_index]\n",
    "                    # Check if the coda plus the next character forms a valid digraph or cluster in consoantes_nao_ca\n",
    "                    potential_digraph = syllable[-1] + next_char\n",
    "                    if next_char in vogais or potential_digraph in consoantes_nao_ca:\n",
    "                        # If coda is followed by a vowel or forms a valid digraph, treat it as the start of the next syllable\n",
    "                        syllable = syllable[:-1]\n",
    "            \n",
    "            if syllable:\n",
    "                identified_syllables.append(syllable)\n",
    "                i += len(syllable)\n",
    "                matched = True\n",
    "                break\n",
    "\n",
    "        if not matched:\n",
    "            i += 1  # If no syllable match, just move to the next character\n",
    "\n",
    "    return identified_syllables\n",
    "\n",
    "df['Identified_Syllables'] = df['Palavra'].apply(lambda word: identify_syllables_in_word(word, vogais, consoantes_ca, consoantes_auxiliares, consoantes_coda, consoantes_nao_ca))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Stress Syllable Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essa palavra é paroxítona\n"
     ]
    }
   ],
   "source": [
    "word = str(\"hoje\").lower()\n",
    "word0 = word.removesuffix('s')\n",
    "word1 = word0[:-2]\n",
    "word2 = word0[:-3]\n",
    "\n",
    "# Listas de Terminações\n",
    "vogox = ['á', 'é', 'ê', 'i', 'í', 'ó', 'ô', 'u', 'ú', 'ã',\n",
    "         'ão', 'õe', 'ãe', 'ém']\n",
    "conox = ['r', 'l', 'z', 'x', 'om', 'im', 'um']\n",
    "vogpro = ['á', 'â', 'é', 'ê', 'í', 'ó', 'ô', 'ú']\n",
    "vogsim = ['a', 'e', 'o']\n",
    "excecao = ['ã']\n",
    "\n",
    "# Grupos de Palavras\n",
    "\n",
    "grupo_a = word0.endswith(tuple(vogox)) #Termina em elementos oxitonos\n",
    "grupo_b = word0.endswith(tuple(conox)) #Termina em consoante\n",
    "grupo_c = bool(set(vogpro) & set(word0)) #Contém vogal acentuada\n",
    "grupo_d = word0.endswith(tuple(vogsim)) #Termina em vogal não-acentuada\n",
    "grupo_e = bool(set(vogpro) & set(word1)) #Contém vogal acentuada (não terminal -2)\n",
    "grupo_f = bool(set(excecao) & set(word0)) #Contém ã\n",
    "grupo_g = bool(set(vogpro) & set(word2)) #Contém vogal acentuada (não terminal -3)\n",
    "\n",
    "# Respostas - Vogais\n",
    "if (grupo_c and grupo_d and grupo_g == True) and grupo_f == False:\n",
    "    print('Essa palavra é proparoxítona')\n",
    "elif grupo_a == True and grupo_e == False:\n",
    "    print('Essa palavra é oxítona')\n",
    "\n",
    "# Respostas - Consoantes\n",
    "\n",
    "elif grupo_b == True and grupo_c == False:\n",
    "    print('Essa palavra é oxítona')\n",
    "\n",
    "elif grupo_b and grupo_c == True:\n",
    "    print('Essa palavra é paroxítona')\n",
    "\n",
    "else:\n",
    "    print('Essa palavra é paroxítona')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
