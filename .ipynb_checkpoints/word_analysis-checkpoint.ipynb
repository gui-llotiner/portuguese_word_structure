{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting Data\n",
    "\n",
    "Collects data from wikipedia pages, saves them and extract unique words and their's frequencies to uses on word structure analysis. It also checks if the language corpora it's already collected to skip calling the API multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libs\n",
    "import wikipedia\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T01:03:41.254522Z",
     "start_time": "2023-08-11T01:03:41.225557Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavra</th>\n",
       "      <th>Frequencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>representante</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4642</th>\n",
       "      <td>detalhadas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4592</th>\n",
       "      <td>industriais</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>deputados</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>malfatti</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>ampliando</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2527</th>\n",
       "      <td>qs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>expandir</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>lançassem</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>blindados</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>coordenador</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4299</th>\n",
       "      <td>tipicamente</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>confederados</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>bilheterias</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>diz</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>vitória</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>influenciado</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4510</th>\n",
       "      <td>desarmado</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325</th>\n",
       "      <td>adequado</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>plano</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Palavra  Frequencia\n",
       "2197  representante           1\n",
       "4642     detalhadas           1\n",
       "4592    industriais           1\n",
       "1979      deputados           8\n",
       "3008       malfatti           1\n",
       "2272      ampliando           1\n",
       "2527             qs           1\n",
       "2201       expandir           1\n",
       "1050      lançassem           1\n",
       "2155      blindados           2\n",
       "1285    coordenador           1\n",
       "4299    tipicamente           1\n",
       "928    confederados           1\n",
       "2890    bilheterias           1\n",
       "4236            diz           4\n",
       "1097        vitória           2\n",
       "1864   influenciado           2\n",
       "4510      desarmado           1\n",
       "4325       adequado           1\n",
       "1253          plano           2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up directory and file paths\n",
    "corpus_dir = Path(\"language_corpora\")\n",
    "corpus_dir.mkdir(exist_ok=True)\n",
    "corpus_file = corpus_dir / \"portuguese_corpus.txt\"\n",
    "\n",
    "# Set Wikipedia language to Portuguese\n",
    "wikipedia.set_lang(\"pt\")\n",
    "\n",
    "# List of common Portuguese Wikipedia page topics\n",
    "search_terms = [\"Brasil\", \"Econômia\", \"Futebol\", \"História\", \"Cultura\"]\n",
    "\n",
    "# Collect text from Wikipedia pages\n",
    "def collect_wikipedia_text(search_terms, results_limit=2):\n",
    "    collected_texts = []\n",
    "    total_words = 0\n",
    "    min_content_length = 500\n",
    "    target_words = 20000\n",
    "\n",
    "    for term in search_terms:\n",
    "        if total_words >= target_words:\n",
    "            break\n",
    "        try:\n",
    "            search_results = wikipedia.search(term, results=results_limit)\n",
    "            for title in search_results:\n",
    "                if total_words >= target_words:\n",
    "                    break\n",
    "                try:\n",
    "                    page = wikipedia.page(title, auto_suggest=False)\n",
    "                    content = page.content\n",
    "                    word_count = len(content.split())\n",
    "                    if word_count > min_content_length:\n",
    "                        collected_texts.append(content)\n",
    "                        total_words += word_count\n",
    "                    time.sleep(1)\n",
    "                except (wikipedia.exceptions.PageError, wikipedia.exceptions.DisambiguationError):\n",
    "                    pass\n",
    "                except Exception:\n",
    "                    pass\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return '\\n'.join(collected_texts)\n",
    "\n",
    "# Check if corpus exists and has sufficient words\n",
    "min_words = 20000\n",
    "if corpus_file.exists():\n",
    "    with open(corpus_file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    word_count = len(text.split())\n",
    "    if word_count >= min_words:\n",
    "        pass  # Use existing corpus\n",
    "    else:\n",
    "        text = collect_wikipedia_text(search_terms)\n",
    "        if text and len(text.split()) >= min_words:\n",
    "            with open(corpus_file, 'w', encoding='utf-8') as f:\n",
    "                f.write(text)\n",
    "else:\n",
    "    text = collect_wikipedia_text(search_terms)\n",
    "    if text and len(text.split()) >= min_words:\n",
    "        with open(corpus_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(text)\n",
    "\n",
    "# Check if text was retrieved or loaded\n",
    "if not text:\n",
    "    exit()\n",
    "\n",
    "# Clean the text: keep letters and diacritics, remove numbers, punctuation, spaces, etc.\n",
    "words = re.findall(r'[a-záéíóúâêîôûãõç]+', text.lower())\n",
    "\n",
    "# Count word frequencies\n",
    "word_counts = Counter(words)\n",
    "\n",
    "# Create DataFrame with words and their frequencies\n",
    "df = pd.DataFrame(list(word_counts.items()), columns=['Palavra', 'Frequencia'])\n",
    "\n",
    "# Sort by frequency and sample 10 random words\n",
    "df = df.sort_values(by='Frequencia', ascending=False).sample(50)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encontrando Sílabas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T01:03:41.270437Z",
     "start_time": "2023-08-11T01:03:41.258469Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cria uma lista de vogais\n",
    "vogais = ['a', 'e', 'i', 'o', 'u', 'á', 'é', 'í', 'ó', 'ú', 'â', 'ê', 'ô', 'ã', 'õ', 'ão', 'õe', 'ãe']\n",
    "\n",
    "# Cria uma lista de consoantes que aceitam CA\n",
    "consoantes_ca = ['b', 'c', 'd', 'f', 'g', 'p', 't']\n",
    "\n",
    "# Cria uma lista de consoantes auxiliares (CA)\n",
    "consoantes_auxiliares = ['l', 'r']\n",
    "\n",
    "# Cria uma lista de consoantes de coda (CC)\n",
    "consoantes_coda = ['m', 'n', 'r', 'l', 'z', 's', 'x']\n",
    "codas = consoantes_coda\n",
    "\n",
    "# Cria uma lista de consoantes que não aceitam CA\n",
    "consoantes_nao_ca = ['h', 'j', 'm', 'n', 'r', 'l', 's', 'v', 'x', 'z', 'lh', 'nh', 'qu', 'gu', 'ch', 'ç']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T01:03:41.300565Z",
     "start_time": "2023-08-11T01:03:41.272432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>silabas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>çãer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4208</th>\n",
       "      <td>çãel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4209</th>\n",
       "      <td>çãez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4210</th>\n",
       "      <td>çães</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4211</th>\n",
       "      <td>çãex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4212 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     silabas\n",
       "0          a\n",
       "1         am\n",
       "2         an\n",
       "3        ans\n",
       "4         ar\n",
       "...      ...\n",
       "4207    çãer\n",
       "4208    çãel\n",
       "4209    çãez\n",
       "4210    çães\n",
       "4211    çãex\n",
       "\n",
       "[4212 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gerar_silabas(vogais, consoantes_ca, consoantes_auxiliares, consoantes_coda, consoantes_nao_ca):\n",
    "    silabas = []\n",
    "    \n",
    "    # Using only vogais\n",
    "    for vogal in vogais:\n",
    "        silabas.append(vogal)\n",
    "        for cc in consoantes_coda:\n",
    "            silabas.append(vogal + cc)\n",
    "            if cc == 'n':\n",
    "                silabas.append(vogal + cc + 's')\n",
    "                \n",
    "    # Using consoantes_ca\n",
    "    for consoante in consoantes_ca:\n",
    "        for vogal in vogais:\n",
    "            silabas.append(consoante + vogal)\n",
    "            for cc in consoantes_coda:\n",
    "                silabas.append(consoante + vogal + cc)\n",
    "                if cc == 'n':\n",
    "                    silabas.append(consoante + vogal + cc + 's')\n",
    "                    \n",
    "    # Using consoantes_auxiliares\n",
    "    for consoante in consoantes_auxiliares:\n",
    "        for vogal in vogais:\n",
    "            silabas.append(consoante + vogal)\n",
    "            for cc in consoantes_coda:\n",
    "                silabas.append(consoante + vogal + cc)\n",
    "                if cc == 'n':\n",
    "                    silabas.append(consoante + vogal + cc + 's')\n",
    "                    \n",
    "    # Using consoantes_nao_ca\n",
    "    for consoante in consoantes_nao_ca:\n",
    "        for vogal in vogais:\n",
    "            silabas.append(consoante + vogal)\n",
    "            for cc in consoantes_coda:\n",
    "                silabas.append(consoante + vogal + cc)\n",
    "                if cc == 'n':\n",
    "                    silabas.append(consoante + vogal + cc + 's')\n",
    "    \n",
    "    return silabas\n",
    "\n",
    "# Chama a função com os parâmetros especificados\n",
    "resultado = gerar_silabas(vogais, consoantes_ca, consoantes_auxiliares, consoantes_coda, consoantes_nao_ca)\n",
    "\n",
    "# Converte em um dataframe\n",
    "silabas = pd.DataFrame(resultado, columns=['silabas'])\n",
    "\n",
    "silabas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T01:03:41.331593Z",
     "start_time": "2023-08-11T01:03:41.318791Z"
    }
   },
   "outputs": [],
   "source": [
    "def match_syllable_from_start(word, patterns, next_char_cond=None):\n",
    "    \"\"\"Return the longest syllable from the start of the word that matches a pattern.\"\"\"\n",
    "    max_syllable = ''\n",
    "    for pattern in patterns:\n",
    "        if word.startswith(pattern) and len(pattern) > len(max_syllable):\n",
    "            # If there's a condition to check the character after the matched pattern\n",
    "            next_char_index = len(pattern)\n",
    "            if next_char_cond:\n",
    "                # Either the word ends after the coda, or the next character satisfies the condition\n",
    "                if next_char_index == len(word) or (next_char_index < len(word) and next_char_cond(word[next_char_index])):\n",
    "                    max_syllable = pattern\n",
    "            else:\n",
    "                max_syllable = pattern\n",
    "    return max_syllable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T01:03:41.363531Z",
     "start_time": "2023-08-11T01:03:41.333578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavra</th>\n",
       "      <th>Frequencia</th>\n",
       "      <th>Identified_Syllables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>representante</td>\n",
       "      <td>1</td>\n",
       "      <td>[re, pre, sen, tan, te]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4642</th>\n",
       "      <td>detalhadas</td>\n",
       "      <td>1</td>\n",
       "      <td>[de, ta, lha, das]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4592</th>\n",
       "      <td>industriais</td>\n",
       "      <td>1</td>\n",
       "      <td>[in, dus, tri, a, is]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>deputados</td>\n",
       "      <td>8</td>\n",
       "      <td>[de, pu, ta, dos]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>malfatti</td>\n",
       "      <td>1</td>\n",
       "      <td>[mal, fa, ti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>ampliando</td>\n",
       "      <td>1</td>\n",
       "      <td>[am, pli, an, do]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2527</th>\n",
       "      <td>qs</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>expandir</td>\n",
       "      <td>1</td>\n",
       "      <td>[ex, pan, dir]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>lançassem</td>\n",
       "      <td>1</td>\n",
       "      <td>[lan, ças, sem]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>blindados</td>\n",
       "      <td>2</td>\n",
       "      <td>[blin, da, dos]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>coordenador</td>\n",
       "      <td>1</td>\n",
       "      <td>[co, or, de, na, dor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4299</th>\n",
       "      <td>tipicamente</td>\n",
       "      <td>1</td>\n",
       "      <td>[ti, pi, ca, men, te]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>confederados</td>\n",
       "      <td>1</td>\n",
       "      <td>[con, fe, de, ra, dos]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>bilheterias</td>\n",
       "      <td>1</td>\n",
       "      <td>[bi, lhe, te, ri, as]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>diz</td>\n",
       "      <td>4</td>\n",
       "      <td>[diz]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>vitória</td>\n",
       "      <td>2</td>\n",
       "      <td>[vi, tó, ri, a]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>influenciado</td>\n",
       "      <td>2</td>\n",
       "      <td>[in, flu, en, ci, a, do]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4510</th>\n",
       "      <td>desarmado</td>\n",
       "      <td>1</td>\n",
       "      <td>[de, sar, ma, do]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325</th>\n",
       "      <td>adequado</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, de, qua, do]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>plano</td>\n",
       "      <td>2</td>\n",
       "      <td>[pla, no]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Palavra  Frequencia      Identified_Syllables\n",
       "2197  representante           1   [re, pre, sen, tan, te]\n",
       "4642     detalhadas           1        [de, ta, lha, das]\n",
       "4592    industriais           1     [in, dus, tri, a, is]\n",
       "1979      deputados           8         [de, pu, ta, dos]\n",
       "3008       malfatti           1             [mal, fa, ti]\n",
       "2272      ampliando           1         [am, pli, an, do]\n",
       "2527             qs           1                        []\n",
       "2201       expandir           1            [ex, pan, dir]\n",
       "1050      lançassem           1           [lan, ças, sem]\n",
       "2155      blindados           2           [blin, da, dos]\n",
       "1285    coordenador           1     [co, or, de, na, dor]\n",
       "4299    tipicamente           1     [ti, pi, ca, men, te]\n",
       "928    confederados           1    [con, fe, de, ra, dos]\n",
       "2890    bilheterias           1     [bi, lhe, te, ri, as]\n",
       "4236            diz           4                     [diz]\n",
       "1097        vitória           2           [vi, tó, ri, a]\n",
       "1864   influenciado           2  [in, flu, en, ci, a, do]\n",
       "4510      desarmado           1         [de, sar, ma, do]\n",
       "4325       adequado           1          [a, de, qua, do]\n",
       "1253          plano           2                 [pla, no]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def identify_syllables_in_word(word, vogais, consoantes_ca, consoantes_auxiliares, consoantes_coda, consoantes_nao_ca):\n",
    "    identified_syllables = []\n",
    "    i = 0\n",
    "\n",
    "    # Patterns list comprehension\n",
    "    ca_vc_coda = [con + ca + v + co for con in consoantes_ca for ca in consoantes_auxiliares for v in vogais for co in consoantes_coda]\n",
    "    c_v_coda = [con + v + co for con in (consoantes_ca + consoantes_nao_ca) for v in vogais for co in consoantes_coda]\n",
    "    ca_v = [con + ca + v for con in consoantes_ca for ca in consoantes_auxiliares for v in vogais]\n",
    "    c_v = [con + v for con in (consoantes_ca + consoantes_nao_ca) for v in vogais]\n",
    "    v_coda = [v + co for v in vogais for co in consoantes_coda]\n",
    "    \n",
    "    while i < len(word):\n",
    "        patterns = [ca_vc_coda, c_v_coda, ca_v, c_v, v_coda, vogais]\n",
    "        \n",
    "        matched = False\n",
    "        for pattern_list in patterns:\n",
    "            syllable = match_syllable_from_start(word[i:], pattern_list)\n",
    "            \n",
    "            # For codas, check if it should be retained as a coda or act as the starting consonant of the next syllable\n",
    "            if syllable and syllable[-1] in consoantes_coda:\n",
    "                next_char_index = i + len(syllable)\n",
    "                if next_char_index < len(word):\n",
    "                    next_char = word[next_char_index]\n",
    "                    # Check if the coda plus the next character forms a valid digraph or cluster in consoantes_nao_ca\n",
    "                    potential_digraph = syllable[-1] + next_char\n",
    "                    if next_char in vogais or potential_digraph in consoantes_nao_ca:\n",
    "                        # If coda is followed by a vowel or forms a valid digraph, treat it as the start of the next syllable\n",
    "                        syllable = syllable[:-1]\n",
    "            \n",
    "            if syllable:\n",
    "                identified_syllables.append(syllable)\n",
    "                i += len(syllable)\n",
    "                matched = True\n",
    "                break\n",
    "\n",
    "        if not matched:\n",
    "            i += 1  # If no syllable match, just move to the next character\n",
    "\n",
    "    return identified_syllables\n",
    "\n",
    "df['Identified_Syllables'] = df['Palavra'].apply(lambda word: identify_syllables_in_word(word, vogais, consoantes_ca, consoantes_auxiliares, consoantes_coda, consoantes_nao_ca))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Stress Syllable Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essa palavra é paroxítona\n"
     ]
    }
   ],
   "source": [
    "word = str(\"hoje\").lower()\n",
    "word0 = word.removesuffix('s')\n",
    "word1 = word0[:-2]\n",
    "word2 = word0[:-3]\n",
    "\n",
    "# Listas de Terminações\n",
    "vogox = ['á', 'é', 'ê', 'i', 'í', 'ó', 'ô', 'u', 'ú', 'ã',\n",
    "         'ão', 'õe', 'ãe', 'ém']\n",
    "conox = ['r', 'l', 'z', 'x', 'om', 'im', 'um']\n",
    "vogpro = ['á', 'â', 'é', 'ê', 'í', 'ó', 'ô', 'ú']\n",
    "vogsim = ['a', 'e', 'o']\n",
    "excecao = ['ã']\n",
    "\n",
    "# Grupos de Palavras\n",
    "\n",
    "grupo_a = word0.endswith(tuple(vogox)) #Termina em elementos oxitonos\n",
    "grupo_b = word0.endswith(tuple(conox)) #Termina em consoante\n",
    "grupo_c = bool(set(vogpro) & set(word0)) #Contém vogal acentuada\n",
    "grupo_d = word0.endswith(tuple(vogsim)) #Termina em vogal não-acentuada\n",
    "grupo_e = bool(set(vogpro) & set(word1)) #Contém vogal acentuada (não terminal -2)\n",
    "grupo_f = bool(set(excecao) & set(word0)) #Contém ã\n",
    "grupo_g = bool(set(vogpro) & set(word2)) #Contém vogal acentuada (não terminal -3)\n",
    "\n",
    "# Respostas - Vogais\n",
    "if (grupo_c and grupo_d and grupo_g == True) and grupo_f == False:\n",
    "    print('Essa palavra é proparoxítona')\n",
    "elif grupo_a == True and grupo_e == False:\n",
    "    print('Essa palavra é oxítona')\n",
    "\n",
    "# Respostas - Consoantes\n",
    "\n",
    "elif grupo_b == True and grupo_c == False:\n",
    "    print('Essa palavra é oxítona')\n",
    "\n",
    "elif grupo_b and grupo_c == True:\n",
    "    print('Essa palavra é paroxítona')\n",
    "\n",
    "else:\n",
    "    print('Essa palavra é paroxítona')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
