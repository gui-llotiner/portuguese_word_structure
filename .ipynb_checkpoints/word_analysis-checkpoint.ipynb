{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Collecting Data\n",
    "\n",
    "Collects data from wikipedia pages, saves them and extract unique words and their's frequencies to uses on word structure analysis. It also checks if the language corpora it's already collected to skip calling the API multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libs\n",
    "import wikipedia\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T01:03:41.254522Z",
     "start_time": "2023-08-11T01:03:41.225557Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavra</th>\n",
       "      <th>Frequencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>dutra</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>sector</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>onde</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4867</th>\n",
       "      <td>futuras</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>antártico</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>guianas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>ameríndias</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4703</th>\n",
       "      <td>reeleitos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615</th>\n",
       "      <td>to</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>tukano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>desmontagem</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>realocação</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3841</th>\n",
       "      <td>carl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>ferrovia</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>alemanha</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>rapidamente</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>oficial</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>possuindo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3295</th>\n",
       "      <td>inativa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4047</th>\n",
       "      <td>internas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4255</th>\n",
       "      <td>respetivas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>título</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>global</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>tradições</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>questão</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>atol</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>representante</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5037</th>\n",
       "      <td>retornos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3385</th>\n",
       "      <td>mediante</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>demografia</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4804</th>\n",
       "      <td>demandantes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4778</th>\n",
       "      <td>vias</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>nasceu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>enviado</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3746</th>\n",
       "      <td>relacionado</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>negro</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4718</th>\n",
       "      <td>programação</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>povos</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4681</th>\n",
       "      <td>incidência</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>manufatura</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3285</th>\n",
       "      <td>feriados</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5011</th>\n",
       "      <td>regulador</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>gasolina</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>leitura</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4048</th>\n",
       "      <td>tecnológicas</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>qual</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780</th>\n",
       "      <td>planificadas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>josé</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3656</th>\n",
       "      <td>barueri</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>deficiência</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Palavra  Frequencia\n",
       "1110          dutra           1\n",
       "4672         sector           1\n",
       "40             onde          20\n",
       "4867        futuras           1\n",
       "2742      antártico           1\n",
       "1568        guianas           1\n",
       "1866     ameríndias           3\n",
       "4703      reeleitos           1\n",
       "3615             to           1\n",
       "1909         tukano           1\n",
       "932     desmontagem           1\n",
       "4227     realocação           1\n",
       "3841           carl           1\n",
       "2658       ferrovia           1\n",
       "1079       alemanha           3\n",
       "1103    rapidamente           1\n",
       "1448        oficial           6\n",
       "2693      possuindo           1\n",
       "3295        inativa           1\n",
       "4047       internas           1\n",
       "4255     respetivas           1\n",
       "3334         título           3\n",
       "286          global           8\n",
       "2826      tradições           1\n",
       "911         questão           8\n",
       "120            atol           2\n",
       "2197  representante           1\n",
       "5037       retornos           1\n",
       "3385       mediante           1\n",
       "1701     demografia           1\n",
       "4804    demandantes           1\n",
       "4778           vias           1\n",
       "2757         nasceu           1\n",
       "1093        enviado           1\n",
       "3746    relacionado           3\n",
       "1603          negro           2\n",
       "4718    programação           1\n",
       "1769          povos           4\n",
       "4681     incidência           1\n",
       "2268     manufatura           2\n",
       "3285       feriados           1\n",
       "5011      regulador           1\n",
       "2594       gasolina           2\n",
       "2476        leitura           3\n",
       "4048   tecnológicas           2\n",
       "236            qual          14\n",
       "4780   planificadas           1\n",
       "352            josé           6\n",
       "3656        barueri           1\n",
       "2506    deficiência           1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up directory and file paths\n",
    "corpus_dir = Path(\"language_corpora\")\n",
    "corpus_dir.mkdir(exist_ok=True)\n",
    "corpus_file = corpus_dir / \"portuguese_corpus.txt\"\n",
    "\n",
    "# Set Wikipedia language to Portuguese\n",
    "wikipedia.set_lang(\"pt\")\n",
    "\n",
    "# List of common Portuguese Wikipedia page topics\n",
    "search_terms = [\"Brasil\", \"Econômia\", \"Futebol\", \"História\", \"Cultura\"]\n",
    "\n",
    "# Collect text from Wikipedia pages\n",
    "def collect_wikipedia_text(search_terms, results_limit=2):\n",
    "    collected_texts = []\n",
    "    total_words = 0\n",
    "    min_content_length = 500\n",
    "    target_words = 20000\n",
    "\n",
    "    for term in search_terms:\n",
    "        if total_words >= target_words:\n",
    "            break\n",
    "        try:\n",
    "            search_results = wikipedia.search(term, results=results_limit)\n",
    "            for title in search_results:\n",
    "                if total_words >= target_words:\n",
    "                    break\n",
    "                try:\n",
    "                    page = wikipedia.page(title, auto_suggest=False)\n",
    "                    content = page.content\n",
    "                    word_count = len(content.split())\n",
    "                    if word_count > min_content_length:\n",
    "                        collected_texts.append(content)\n",
    "                        total_words += word_count\n",
    "                    time.sleep(1)\n",
    "                except (wikipedia.exceptions.PageError, wikipedia.exceptions.DisambiguationError):\n",
    "                    pass\n",
    "                except Exception:\n",
    "                    pass\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return '\\n'.join(collected_texts)\n",
    "\n",
    "# Check if corpus exists and has sufficient words\n",
    "min_words = 20000\n",
    "if corpus_file.exists():\n",
    "    with open(corpus_file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    word_count = len(text.split())\n",
    "    if word_count >= min_words:\n",
    "        pass  # Use existing corpus\n",
    "    else:\n",
    "        text = collect_wikipedia_text(search_terms)\n",
    "        if text and len(text.split()) >= min_words:\n",
    "            with open(corpus_file, 'w', encoding='utf-8') as f:\n",
    "                f.write(text)\n",
    "else:\n",
    "    text = collect_wikipedia_text(search_terms)\n",
    "    if text and len(text.split()) >= min_words:\n",
    "        with open(corpus_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(text)\n",
    "\n",
    "# Check if text was retrieved or loaded\n",
    "if not text:\n",
    "    exit()\n",
    "\n",
    "# Clean the text: keep letters and diacritics, remove numbers, punctuation, spaces, etc.\n",
    "words = re.findall(r'[a-záéíóúâêîôûãõç]+', text.lower())\n",
    "\n",
    "# Count word frequencies\n",
    "word_counts = Counter(words)\n",
    "\n",
    "# Create DataFrame with words and their frequencies\n",
    "df = pd.DataFrame(list(word_counts.items()), columns=['Palavra', 'Frequencia'])\n",
    "\n",
    "# Sort by frequency and sample 10 random words\n",
    "df = df.sort_values(by='Frequencia', ascending=False).sample(50)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encontrando Sílabas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T01:03:41.270437Z",
     "start_time": "2023-08-11T01:03:41.258469Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cria uma lista de vogais\n",
    "vogais = ['a', 'e', 'i', 'o', 'u', 'á', 'é', 'í', 'ó', 'ú', 'â', 'ê', 'ô', 'ã', 'õ', 'ão', 'õe', 'ãe']\n",
    "\n",
    "# Cria uma lista de consoantes que aceitam CA\n",
    "consoantes_ca = ['b', 'c', 'd', 'f', 'g', 'p', 't', 'v']\n",
    "\n",
    "# Cria uma lista de consoantes auxiliares (CA)\n",
    "consoantes_auxiliares = ['l', 'r']\n",
    "\n",
    "# Cria uma lista de consoantes de coda (CC)\n",
    "consoantes_coda = ['m', 'n', 'r', 'l', 'z', 's', 'x', 'ns', 'rs', 'bs']\n",
    "codas = consoantes_coda\n",
    "\n",
    "# Cria uma lista de consoantes que não aceitam CA\n",
    "consoantes_nao_ca = ['h', 'j', 'm', 'n', 'r', 'l', 's', 'x', 'z', 'lh', 'nh', 'qu', 'gu', 'cl', 'ch', 'ç']\n",
    "\n",
    "# Cria uma lista de consoantes não-coda que podem aparecer no final de sílabas\n",
    "non_coda_end_consonants = ['p', 'd', 'b', 'c', 'g', 't']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T01:03:41.300565Z",
     "start_time": "2023-08-11T01:03:41.272432Z"
    }
   },
   "outputs": [],
   "source": [
    "def gerar_silabas(vogais, consoantes_ca, consoantes_auxiliares, consoantes_coda, consoantes_nao_ca):\n",
    "    silabas = []\n",
    "    \n",
    "    # Using only vogais\n",
    "    for vogal in vogais:\n",
    "        silabas.append(vogal)\n",
    "        for cc in consoantes_coda:\n",
    "            silabas.append(vogal + cc)\n",
    "            if cc == 'n':\n",
    "                silabas.append(vogal + cc + 's')\n",
    "                \n",
    "    # Using consoantes_ca\n",
    "    for consoante in consoantes_ca:\n",
    "        for vogal in vogais:\n",
    "            silabas.append(consoante + vogal)\n",
    "            for cc in consoantes_coda:\n",
    "                silabas.append(consoante + vogal + cc)\n",
    "                if cc == 'n':\n",
    "                    silabas.append(consoante + vogal + cc + 's')\n",
    "                    \n",
    "    # Using consoantes_auxiliares\n",
    "    for consoante in consoantes_auxiliares:\n",
    "        for vogal in vogais:\n",
    "            silabas.append(consoante + vogal)\n",
    "            for cc in consoantes_coda:\n",
    "                silabas.append(consoante + vogal + cc)\n",
    "                if cc == 'n':\n",
    "                    silabas.append(consoante + vogal + cc + 's')\n",
    "                    \n",
    "    # Using consoantes_nao_ca\n",
    "    for consoante in consoantes_nao_ca:\n",
    "        for vogal in vogais:\n",
    "            silabas.append(consoante + vogal)\n",
    "            for cc in consoantes_coda:\n",
    "                silabas.append(consoante + vogal + cc)\n",
    "                if cc == 'n':\n",
    "                    silabas.append(consoante + vogal + cc + 's')\n",
    "    \n",
    "    return silabas\n",
    "\n",
    "# Chama a função com os parâmetros especificados\n",
    "resultado = gerar_silabas(vogais, consoantes_ca, consoantes_auxiliares, consoantes_coda, consoantes_nao_ca)\n",
    "\n",
    "# Converte em um dataframe\n",
    "silabas = pd.DataFrame(resultado, columns=['silabas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T01:03:41.331593Z",
     "start_time": "2023-08-11T01:03:41.318791Z"
    }
   },
   "outputs": [],
   "source": [
    "def match_syllable_from_start(word, patterns, next_char_cond=None):\n",
    "    \"\"\"Return the longest syllable from the start of the word that matches a pattern.\"\"\"\n",
    "    max_syllable = ''\n",
    "    for pattern in patterns:\n",
    "        if word.startswith(pattern) and len(pattern) > len(max_syllable):\n",
    "            # If there's a condition to check the character after the matched pattern\n",
    "            next_char_index = len(pattern)\n",
    "            if next_char_cond:\n",
    "                # Either the word ends after the coda, or the next character satisfies the condition\n",
    "                if next_char_index == len(word) or (next_char_index < len(word) and next_char_cond(word[next_char_index])):\n",
    "                    max_syllable = pattern\n",
    "            else:\n",
    "                max_syllable = pattern\n",
    "    return max_syllable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T01:03:41.363531Z",
     "start_time": "2023-08-11T01:03:41.333578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavra</th>\n",
       "      <th>Frequencia</th>\n",
       "      <th>Identified_Syllables</th>\n",
       "      <th>Syllable_Length_Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>dutra</td>\n",
       "      <td>1</td>\n",
       "      <td>[du, tra]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>sector</td>\n",
       "      <td>1</td>\n",
       "      <td>[sec, tor]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>onde</td>\n",
       "      <td>20</td>\n",
       "      <td>[on, de]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4867</th>\n",
       "      <td>futuras</td>\n",
       "      <td>1</td>\n",
       "      <td>[fu, tu, ras]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>antártico</td>\n",
       "      <td>1</td>\n",
       "      <td>[an, tár, ti, co]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>guianas</td>\n",
       "      <td>1</td>\n",
       "      <td>[gui, a, nas]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>ameríndias</td>\n",
       "      <td>3</td>\n",
       "      <td>[a, me, rín, di, as]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4703</th>\n",
       "      <td>reeleitos</td>\n",
       "      <td>1</td>\n",
       "      <td>[re, e, le, i, tos]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615</th>\n",
       "      <td>to</td>\n",
       "      <td>1</td>\n",
       "      <td>[to]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>tukano</td>\n",
       "      <td>1</td>\n",
       "      <td>[tu, a, no]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>desmontagem</td>\n",
       "      <td>1</td>\n",
       "      <td>[des, mon, ta, gem]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>realocação</td>\n",
       "      <td>1</td>\n",
       "      <td>[re, a, lo, ca, ção]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3841</th>\n",
       "      <td>carl</td>\n",
       "      <td>1</td>\n",
       "      <td>[car]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>ferrovia</td>\n",
       "      <td>1</td>\n",
       "      <td>[fer, ro, vi, a]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>alemanha</td>\n",
       "      <td>3</td>\n",
       "      <td>[a, le, ma, nha]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>rapidamente</td>\n",
       "      <td>1</td>\n",
       "      <td>[ra, pi, da, men, te]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>oficial</td>\n",
       "      <td>6</td>\n",
       "      <td>[o, fi, ci, al]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>possuindo</td>\n",
       "      <td>1</td>\n",
       "      <td>[pos, su, in, do]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3295</th>\n",
       "      <td>inativa</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, na, ti, va]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4047</th>\n",
       "      <td>internas</td>\n",
       "      <td>1</td>\n",
       "      <td>[in, ter, nas]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4255</th>\n",
       "      <td>respetivas</td>\n",
       "      <td>1</td>\n",
       "      <td>[res, pe, ti, vas]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>título</td>\n",
       "      <td>3</td>\n",
       "      <td>[tí, tu, lo]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>global</td>\n",
       "      <td>8</td>\n",
       "      <td>[glo, bal]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>tradições</td>\n",
       "      <td>1</td>\n",
       "      <td>[tra, di, ções]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>questão</td>\n",
       "      <td>8</td>\n",
       "      <td>[ques, tão]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>atol</td>\n",
       "      <td>2</td>\n",
       "      <td>[a, tol]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>representante</td>\n",
       "      <td>1</td>\n",
       "      <td>[re, pre, sen, tan, te]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5037</th>\n",
       "      <td>retornos</td>\n",
       "      <td>1</td>\n",
       "      <td>[re, tor, nos]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3385</th>\n",
       "      <td>mediante</td>\n",
       "      <td>1</td>\n",
       "      <td>[me, di, an, te]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>demografia</td>\n",
       "      <td>1</td>\n",
       "      <td>[de, mo, gra, fi, a]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4804</th>\n",
       "      <td>demandantes</td>\n",
       "      <td>1</td>\n",
       "      <td>[de, man, dan, tes]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4778</th>\n",
       "      <td>vias</td>\n",
       "      <td>1</td>\n",
       "      <td>[vi, as]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>nasceu</td>\n",
       "      <td>1</td>\n",
       "      <td>[nas, ce, u]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>enviado</td>\n",
       "      <td>1</td>\n",
       "      <td>[en, vi, a, do]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3746</th>\n",
       "      <td>relacionado</td>\n",
       "      <td>3</td>\n",
       "      <td>[re, la, ci, o, na, do]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>negro</td>\n",
       "      <td>2</td>\n",
       "      <td>[ne, gro]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4718</th>\n",
       "      <td>programação</td>\n",
       "      <td>1</td>\n",
       "      <td>[pro, gra, ma, ção]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>povos</td>\n",
       "      <td>4</td>\n",
       "      <td>[po, vos]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4681</th>\n",
       "      <td>incidência</td>\n",
       "      <td>1</td>\n",
       "      <td>[in, ci, dên, ci, a]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>manufatura</td>\n",
       "      <td>2</td>\n",
       "      <td>[ma, nu, fa, tu, ra]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3285</th>\n",
       "      <td>feriados</td>\n",
       "      <td>1</td>\n",
       "      <td>[fe, ri, a, dos]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5011</th>\n",
       "      <td>regulador</td>\n",
       "      <td>1</td>\n",
       "      <td>[re, gu, la, dor]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>gasolina</td>\n",
       "      <td>2</td>\n",
       "      <td>[ga, so, li, na]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>leitura</td>\n",
       "      <td>3</td>\n",
       "      <td>[le, i, tu, ra]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4048</th>\n",
       "      <td>tecnológicas</td>\n",
       "      <td>2</td>\n",
       "      <td>[tec, no, ló, gi, cas]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>qual</td>\n",
       "      <td>14</td>\n",
       "      <td>[qual]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780</th>\n",
       "      <td>planificadas</td>\n",
       "      <td>1</td>\n",
       "      <td>[pla, ni, fi, ca, das]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>josé</td>\n",
       "      <td>6</td>\n",
       "      <td>[jo, sé]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3656</th>\n",
       "      <td>barueri</td>\n",
       "      <td>1</td>\n",
       "      <td>[ba, ru, e, ri]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>deficiência</td>\n",
       "      <td>1</td>\n",
       "      <td>[de, fi, ci, ên, ci, a]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Palavra  Frequencia     Identified_Syllables  \\\n",
       "1110          dutra           1                [du, tra]   \n",
       "4672         sector           1               [sec, tor]   \n",
       "40             onde          20                 [on, de]   \n",
       "4867        futuras           1            [fu, tu, ras]   \n",
       "2742      antártico           1        [an, tár, ti, co]   \n",
       "1568        guianas           1            [gui, a, nas]   \n",
       "1866     ameríndias           3     [a, me, rín, di, as]   \n",
       "4703      reeleitos           1      [re, e, le, i, tos]   \n",
       "3615             to           1                     [to]   \n",
       "1909         tukano           1              [tu, a, no]   \n",
       "932     desmontagem           1      [des, mon, ta, gem]   \n",
       "4227     realocação           1     [re, a, lo, ca, ção]   \n",
       "3841           carl           1                    [car]   \n",
       "2658       ferrovia           1         [fer, ro, vi, a]   \n",
       "1079       alemanha           3         [a, le, ma, nha]   \n",
       "1103    rapidamente           1    [ra, pi, da, men, te]   \n",
       "1448        oficial           6          [o, fi, ci, al]   \n",
       "2693      possuindo           1        [pos, su, in, do]   \n",
       "3295        inativa           1          [i, na, ti, va]   \n",
       "4047       internas           1           [in, ter, nas]   \n",
       "4255     respetivas           1       [res, pe, ti, vas]   \n",
       "3334         título           3             [tí, tu, lo]   \n",
       "286          global           8               [glo, bal]   \n",
       "2826      tradições           1          [tra, di, ções]   \n",
       "911         questão           8              [ques, tão]   \n",
       "120            atol           2                 [a, tol]   \n",
       "2197  representante           1  [re, pre, sen, tan, te]   \n",
       "5037       retornos           1           [re, tor, nos]   \n",
       "3385       mediante           1         [me, di, an, te]   \n",
       "1701     demografia           1     [de, mo, gra, fi, a]   \n",
       "4804    demandantes           1      [de, man, dan, tes]   \n",
       "4778           vias           1                 [vi, as]   \n",
       "2757         nasceu           1             [nas, ce, u]   \n",
       "1093        enviado           1          [en, vi, a, do]   \n",
       "3746    relacionado           3  [re, la, ci, o, na, do]   \n",
       "1603          negro           2                [ne, gro]   \n",
       "4718    programação           1      [pro, gra, ma, ção]   \n",
       "1769          povos           4                [po, vos]   \n",
       "4681     incidência           1     [in, ci, dên, ci, a]   \n",
       "2268     manufatura           2     [ma, nu, fa, tu, ra]   \n",
       "3285       feriados           1         [fe, ri, a, dos]   \n",
       "5011      regulador           1        [re, gu, la, dor]   \n",
       "2594       gasolina           2         [ga, so, li, na]   \n",
       "2476        leitura           3          [le, i, tu, ra]   \n",
       "4048   tecnológicas           2   [tec, no, ló, gi, cas]   \n",
       "236            qual          14                   [qual]   \n",
       "4780   planificadas           1   [pla, ni, fi, ca, das]   \n",
       "352            josé           6                 [jo, sé]   \n",
       "3656        barueri           1          [ba, ru, e, ri]   \n",
       "2506    deficiência           1  [de, fi, ci, ên, ci, a]   \n",
       "\n",
       "      Syllable_Length_Match  \n",
       "1110                   True  \n",
       "4672                   True  \n",
       "40                     True  \n",
       "4867                   True  \n",
       "2742                   True  \n",
       "1568                   True  \n",
       "1866                   True  \n",
       "4703                   True  \n",
       "3615                   True  \n",
       "1909                  False  \n",
       "932                    True  \n",
       "4227                   True  \n",
       "3841                  False  \n",
       "2658                   True  \n",
       "1079                   True  \n",
       "1103                   True  \n",
       "1448                   True  \n",
       "2693                   True  \n",
       "3295                   True  \n",
       "4047                   True  \n",
       "4255                   True  \n",
       "3334                   True  \n",
       "286                    True  \n",
       "2826                   True  \n",
       "911                    True  \n",
       "120                    True  \n",
       "2197                   True  \n",
       "5037                   True  \n",
       "3385                   True  \n",
       "1701                   True  \n",
       "4804                   True  \n",
       "4778                   True  \n",
       "2757                   True  \n",
       "1093                   True  \n",
       "3746                   True  \n",
       "1603                   True  \n",
       "4718                   True  \n",
       "1769                   True  \n",
       "4681                   True  \n",
       "2268                   True  \n",
       "3285                   True  \n",
       "5011                   True  \n",
       "2594                   True  \n",
       "2476                   True  \n",
       "4048                   True  \n",
       "236                    True  \n",
       "4780                   True  \n",
       "352                    True  \n",
       "3656                   True  \n",
       "2506                   True  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def identify_syllables_in_word(word, vogais, consoantes_ca, consoantes_auxiliares, consoantes_coda, consoantes_nao_ca):\n",
    "    identified_syllables = []\n",
    "    i = 0\n",
    "\n",
    "    # Patterns list comprehension\n",
    "    ca_vc_coda = [con + ca + v + co for con in consoantes_ca for ca in consoantes_auxiliares for v in vogais for co in consoantes_coda]\n",
    "    c_v_coda = [con + v + co for con in (consoantes_ca + consoantes_nao_ca) for v in vogais for co in consoantes_coda]\n",
    "    ca_v = [con + ca + v for con in consoantes_ca for ca in consoantes_auxiliares for v in vogais]\n",
    "    c_v = [con + v for con in (consoantes_ca + consoantes_nao_ca) for v in vogais]\n",
    "    v_coda = [v + co for v in vogais for co in consoantes_coda]\n",
    "    \n",
    "    while i < len(word):\n",
    "        # Prioritize patterns with consonants first to avoid matching standalone vowels too early\n",
    "        patterns = [ca_vc_coda, c_v_coda, ca_v, c_v, v_coda, vogais]\n",
    "        \n",
    "        matched = False\n",
    "        for pattern_list in patterns:\n",
    "            syllable = match_syllable_from_start(word[i:], pattern_list)\n",
    "            \n",
    "            # For codas, check if it should be retained as a coda or act as the starting consonant of the next syllable\n",
    "            if syllable and syllable[-1] in consoantes_coda:\n",
    "                next_char_index = i + len(syllable)\n",
    "                if next_char_index < len(word):\n",
    "                    next_char = word[next_char_index]\n",
    "                    # Check if the coda plus the next character forms a valid digraph or cluster in consoantes_nao_ca\n",
    "                    potential_digraph = syllable[-1] + next_char\n",
    "                    if next_char in vogais or potential_digraph in consoantes_nao_ca:\n",
    "                        # If coda is followed by a vowel or forms a valid digraph, treat it as the start of the next syllable\n",
    "                        syllable = syllable[:-1]\n",
    "            \n",
    "            if syllable:\n",
    "                identified_syllables.append(syllable)\n",
    "                i += len(syllable)\n",
    "                matched = True\n",
    "                break\n",
    "\n",
    "        if not matched:\n",
    "            # If no match and there’s a previous syllable, check if the current character can be appended\n",
    "            if i < len(word) and identified_syllables and word[i] in non_coda_end_consonants:\n",
    "                identified_syllables[-1] += word[i]\n",
    "                i += 1\n",
    "            else:\n",
    "                i += 1  # Move to the next character if no match or no previous syllable\n",
    "\n",
    "    # Handle non-coda consonants at the word's end\n",
    "    if i < len(word) and identified_syllables:\n",
    "        remaining = word[i:]\n",
    "        if remaining in non_coda_end_consonants:\n",
    "            identified_syllables[-1] += remaining\n",
    "            i += len(remaining)\n",
    "\n",
    "    return identified_syllables\n",
    "\n",
    "df['Identified_Syllables'] = df['Palavra'].apply(lambda word: identify_syllables_in_word(word, vogais, consoantes_ca, consoantes_auxiliares, consoantes_coda, consoantes_nao_ca))\n",
    "\n",
    "df['Syllable_Length_Match'] = df.apply(lambda row: len(''.join(row['Identified_Syllables'])) == len(row['Palavra']), axis=1)\n",
    "incorrect_syllables_df = df[~df['Syllable_Length_Match']][['Palavra', 'Identified_Syllables']]\n",
    "\n",
    "#incorrect_syllables_df\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stress Syllable Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essa palavra é paroxítona\n"
     ]
    }
   ],
   "source": [
    "word = str(\"hoje\").lower()\n",
    "word0 = word.removesuffix('s')\n",
    "word1 = word0[:-2]\n",
    "word2 = word0[:-3]\n",
    "\n",
    "# Listas de Terminações\n",
    "vogox = ['á', 'é', 'ê', 'i', 'í', 'ó', 'ô', 'u', 'ú', 'ã',\n",
    "         'ão', 'õe', 'ãe', 'ém']\n",
    "conox = ['r', 'l', 'z', 'x', 'om', 'im', 'um']\n",
    "vogpro = ['á', 'â', 'é', 'ê', 'í', 'ó', 'ô', 'ú']\n",
    "vogsim = ['a', 'e', 'o']\n",
    "excecao = ['ã']\n",
    "\n",
    "# Grupos de Palavras\n",
    "\n",
    "grupo_a = word0.endswith(tuple(vogox)) #Termina em elementos oxitonos\n",
    "grupo_b = word0.endswith(tuple(conox)) #Termina em consoante\n",
    "grupo_c = bool(set(vogpro) & set(word0)) #Contém vogal acentuada\n",
    "grupo_d = word0.endswith(tuple(vogsim)) #Termina em vogal não-acentuada\n",
    "grupo_e = bool(set(vogpro) & set(word1)) #Contém vogal acentuada (não terminal -2)\n",
    "grupo_f = bool(set(excecao) & set(word0)) #Contém ã\n",
    "grupo_g = bool(set(vogpro) & set(word2)) #Contém vogal acentuada (não terminal -3)\n",
    "\n",
    "# Respostas - Vogais\n",
    "if (grupo_c and grupo_d and grupo_g == True) and grupo_f == False:\n",
    "    print('Essa palavra é proparoxítona')\n",
    "elif grupo_a == True and grupo_e == False:\n",
    "    print('Essa palavra é oxítona')\n",
    "\n",
    "# Respostas - Consoantes\n",
    "\n",
    "elif grupo_b == True and grupo_c == False:\n",
    "    print('Essa palavra é oxítona')\n",
    "\n",
    "elif grupo_b and grupo_c == True:\n",
    "    print('Essa palavra é paroxítona')\n",
    "\n",
    "else:\n",
    "    print('Essa palavra é paroxítona')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
